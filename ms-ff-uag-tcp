#!/usr/bin/env python3

# ToDo: multiple connections?

import asyncio

try:
    import signal
except ImportError:
    signal = None

from collections import OrderedDict
from collections import namedtuple

import concurrent.futures

import re
import sys
import time
import os.path
import datetime
import random

import logging
import argparse

import urllib.request
import ssl
import configparser

from urllib.parse import urljoin
from urllib.parse import quote

from http.cookiejar import CookieJar
from http.cookiejar import DefaultCookiePolicy

from bs4 import BeautifulSoup

from requests_toolbelt import MultipartEncoder
from keepalive import HTTPHandler


log = logging.getLogger(__name__)
config = None
# sys.setcheckinterval(0)

ALARM_GARBAGE_SIZE = 1024*1024*4
BIG_GARBAGE_SIZE = 1024*1024*2

BUFFER_SIZE = 1024*768
SMALL_BUFFER_SIZE = 1024*64
NEXT_TICK = 0.01


ARGS = argparse.ArgumentParser(description="ms-ff-uag-tcp")

# modern UA, otherwise it thinks i'm on mobile
USER_AGENT = ("Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
              "(KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36")

ACCEPT = "*/*"
ALLOW_REDIRECT = True


ARGS.add_argument(
    '--config', action="store", dest='config', default='config', type=str,
    help='path to config (relative to script directory)')

ARGS.add_argument(
    '--server', action="store", dest='server',
    type=str, help='Server mode: connect to that address')

ARGS.add_argument(
    '--client', action="store", dest='client',
    type=str, help='Client mode: listen to address for connections')

ARGS.add_argument(
    '--init', action="store_true", help='init the directory')

ARGS.add_argument(
    '--clean', action="store_true", help='clean the directory')


ARGS.add_argument(
    '--quiet', action="store", dest='quiet',
    default=0, type=int, help="Don't show debug info")


class NoRedirect(urllib.request.HTTPRedirectHandler):
    def redirect_request(self, req, fp, code, msg, hdrs, newurl):
        if ALLOW_REDIRECT:
            # print("ALLOWED")
            return urllib.request.HTTPRedirectHandler.redirect_request(
                self, req, fp, code, msg, hdrs, newurl)
        else:
            # print("NOT ALLOWED")
            return None


PckTask = namedtuple('PckTask', 'idx, task, is_scavenged')


ListDir = namedtuple('ListDir', 'is_file, name')


class Address:
    host = None
    port = None

    def __new__(cls, addr):
        try:
            Address._parse_init_arg(addr)
            return super(Address, cls).__new__(cls)
        except (AttributeError, KeyError) as e:
            return None

    def __init__(self, addr):
        self.host, self.port = Address._parse_init_arg(addr)

    @staticmethod
    def _parse_init_arg(addr):
        addr = addr.split(":")
        return addr[0], int(addr[1])

    def __str__(self):
        return 'Address(host="%s", port=%d)' % (self.host, self.port)

    __repr__ = __str__


class connectionHandle:
    uagnet = None

    reader = None
    writer = None

    is_connected_or_connecting = False

    def __init__(self, uagnet):
        self.uagnet = uagnet


class uagNetworkHandle:

    token = ''
    uag = None

    def __init__(self, uag):
        self.uag = uag

    @staticmethod
    def pck_uri(token, line, idx):
        return ".ms-ff-uag-tcp-data/%s-est/line-%s/pck-%s.bin" % (
            token, line, str(idx).zfill(8))

    @staticmethod
    def pck_uri_to_idx(uri):
        return int(os.path.basename(uri).replace(
            'pck-', '').replace('.bin', ''))

    @staticmethod
    def conn_uri_to_token(uri):
        return os.path.basename(uri).replace('.con', '')

    @staticmethod
    def gen_token():
        return datetime.datetime.now().strftime("%H_%M-%d-%m-%Y_") + (
            '%08X' % random.randrange(16**8))

    def do_syn(self):
        self.uag.put_file(
            ".ms-ff-uag-tcp-data/to-connect/%s.con" % self.token, b'')

    def lookup_syns(self):
        return self.uag.list_folder(".ms-ff-uag-tcp-data/to-connect/")

    def do_synack(self):
        self.uag.create_folder(
            ".ms-ff-uag-tcp-data/%s-est" % self.token)
        self.uag.create_folder(
            ".ms-ff-uag-tcp-data/%s-est/line-mister" % self.token)
        self.uag.create_folder(
            ".ms-ff-uag-tcp-data/%s-est/line-valet" % self.token)
        self.uag.delete_file(
            ".ms-ff-uag-tcp-data/to-connect/%s.con" % self.token)

    def lookup_synack(self):
        return self.uag.list_folder(
            ".ms-ff-uag-tcp-data/%s-est/" % self.token)

    def commence_packet(self, line, idx, handle_youself=False):
        if not handle_youself:
            return self.uag.get_content(
                uagNetworkHandle.pck_uri(self.token, line, idx))
        else:
            return self.uag.get_content(
                uagNetworkHandle.pck_uri(self.token, line, idx), handle_youself=True)



    def send_packet(self, line, idx, packet):
        self.uag.put_file(
            uagNetworkHandle.pck_uri(self.token, line, idx), packet)

    def unrecieved_packets(self, line):
        return self.uag.list_folder(
            ".ms-ff-uag-tcp-data/%s-est/line-%s" % (self.token, line))

    def ack_packet(self, line, idx):
        self.uag.delete_file(uagNetworkHandle.pck_uri(self.token, line, idx))


class UAGSession:
    """Class for working with UAG"""

    opener = None
    home_url = None

    def __init__(self, opener):
        # super(UAGSession, self).__init__()
        self.opener = opener

    def perform_auth(self):
        url = urllib.request.Request("https://" + config['auth']['domain'] + "/")
        url.add_header("User-Agent", USER_AGENT)
        url.add_header("Accept", ACCEPT)

        r = self.opener.open(url)

        login_url = r.url
        html_doc = r.read().decode('utf-8')
        logging.info(login_url)
        # logging.debug(html_doc)

        soup = BeautifulSoup(html_doc, 'html.parser')
        post_url = soup.find(id="form1").get("action")

        uag_dummy_repository = soup.find(id="form1").find(
            "input", {"name": "dummy_repository"}).get("value")

        uag_repository = soup.find(id="form1").find(
            "input", {"name": "repository"}).get("value")

        post_data = {
            "dummy_repository": uag_dummy_repository,
            "repository": uag_repository,
            "user_name": config['auth']['username'],
            "password": config['auth']['password'],
            "site_name": "fileaccess",
            "secure": "1",
            "resource_id": "2",
            "login_type": "3",
        }

        details = urllib.parse.urlencode(post_data).encode('UTF-8')
        url = urllib.request.Request(urljoin(login_url, post_url), details)
        url.add_header("User-Agent", USER_AGENT)
        url.add_header("Accept", ACCEPT)

        r = self.opener.open(url)

        html_doc = r.read().decode('utf-8', 'ignore')

        if False:
            new_url = re.search(
                'window\.location\.replace\("([^"]+)"\)', html_doc).group(1)

            logging.info(r.url)
            # logging.debug(html_doc)

            url = urllib.request.Request(urljoin(r.url, new_url))
            url.add_header("User-Agent", USER_AGENT)
            url.add_header("Accept", ACCEPT)

            r = self.opener.open(url)

            html_doc = r.read().decode('utf-8', 'ignore')

        main_url = r.url
        logging.info(r.url)
        # logging.debug(html_doc)

        self.main_url = main_url

    def put_file(self, file, file_content):

        folder = config['fileaccess']['directory'] + "/" + file
        folder_escaped = quote(folder, safe='')
        folder_canonical = folder.replace('/', '\\').replace('\\\\', '//')

        create_folder_url = urljoin(
            self.main_url,
            "../filesharing/FileSharingExt/ShareAccessExt.dll?P=" +
            folder_escaped + "&overwrite=on")

        files = OrderedDict([
            ("Filedata", (file, file_content, 'application/octet-stream')),
            ("remotefile", config['fileaccess']['directory']),
            ("remotefilename", folder_canonical),
            ("overwrite", "on"),
        ])

        encoder = MultipartEncoder(files)
        body2 = encoder.to_string()

        url = urllib.request.Request(create_folder_url, body2)

        url.add_header("User-Agent", USER_AGENT)
        url.add_header("Accept", ACCEPT)
        url.add_header("Content-Type", encoder.content_type)
        url.add_header("Content-Length", str(len(body2)))

        try:
            r = self.opener.open(url)
        except urllib.error.HTTPError:
            html_doc = ''
        else:
            pass
            # html_doc = r.read().decode('utf-8', 'ignore')

        # return html_doc
        return b'ok'

    def create_folder(self, directory):

        folder = config['fileaccess']['directory'] + "/" + directory
        folder_escaped = quote(folder, safe='')

        create_folder_url = urljoin(
            self.main_url,
            "../filesharing/newfolder.asp?Folder=" + folder_escaped)

        files = OrderedDict([
            ("Filedata", directory),
            ("remotefile", config['fileaccess']['directory']),
            ("submit1", "Create Folder"),
        ])

        encoder = MultipartEncoder(files)
        body2 = encoder.to_string()

        url = urllib.request.Request(create_folder_url, body2)

        url.add_header("User-Agent", USER_AGENT)
        url.add_header("Accept", ACCEPT)
        url.add_header("Content-Type", encoder.content_type)
        url.add_header("Content-Length", str(len(body2)))

        try:
            r = self.opener.open(url)
        except urllib.error.HTTPError:
            html_doc = ''
        else:
            html_doc = r.read().decode('utf-8', 'ignore')

        return html_doc

    def list_folder(self, directory):

        folder = config['fileaccess']['directory'] + "/" + directory
        folder_escaped = quote(folder, safe='')

        create_folder_url = urljoin(
            self.main_url,
            "../filesharing/filelist.asp?S=" + folder_escaped + "&T=9")

        url = urllib.request.Request(create_folder_url)

        url.add_header("User-Agent", USER_AGENT)
        url.add_header("Accept", ACCEPT)

        try:
            r = self.opener.open(url)
        except urllib.error.HTTPError:
            return []  # Empty directory
        else:
            html_doc = r.read().decode('utf-8', 'ignore')

        results = []
        try:
            soup = BeautifulSoup(html_doc, 'html.parser')
            file_nodes = soup.find(id="fileListTable").find(
                "tbody").find_all("label")
            for i in file_nodes:
                if i.get("onmousedown").find('isFile = true') != -1:
                    isFile = True
                else:
                    isFile = False

                results.append(ListDir(isFile, i.find('nobr').text))
        except Exception:
            results = None  # Non-existant directory

        return results

    def delete_file(self, file):

        folder = config['fileaccess']['directory'] + "/" + file
        folder_escaped = quote(folder, safe='')

        create_folder_url = urljoin(
            self.main_url,
            "../filesharing/filelist.asp?S=" + folder_escaped +
            "&action=1&T=9")

        url = urllib.request.Request(create_folder_url)

        url.add_header("User-Agent", USER_AGENT)
        url.add_header("Accept", ACCEPT)

        try:
            r = self.opener.open(url)
        except urllib.error.HTTPError:
            html_doc = ''
        else:
            html_doc = r.read().decode('utf-8', 'ignore')

        return html_doc

    def get_content(self, file, handle_youself=False):

        folder = config['fileaccess']['directory'] + "/" + file
        folder_escaped = quote(folder, safe='')

        create_folder_url = urljoin(
            self.main_url,
            "../filesharing/FileSharingExt/?OPEN&P=" + folder_escaped)

        url = urllib.request.Request(create_folder_url)

        url.add_header("User-Agent", USER_AGENT)
        url.add_header("Accept", ACCEPT)

        xvgd = False

        try:
            r = self.opener.open(url)

            if handle_youself:
                xvgd = True
                doc = r.read()
            else:
                xvgd = False
                doc = r.read(100)

            doc_text = doc.decode('cp437', 'ignore')
            is_404 = doc_text.find("content='0;URL=errorPage.asp?error=404")

        except urllib.error.HTTPError:
            doc = ''
            doc_text = ''
            is_404 = 1

        if doc == '' or is_404 != -1:
            return (None, None, file, xvgd)

        return (doc, r, file, xvgd)

import threading
scavenger_lock = threading.Lock()


class ScavengerContext:
    tasks = None
    tasks_id = 1


def future_async(*args, timeout=0):
    if not timeout:
        log.debug("NO TIME"+str(args[0]))
        return asyncio.ensure_future(loop.run_in_executor(None, *args))
    else:
        log.debug("TIMEOUT SET"+str(args[0]))
        return asyncio.ensure_future(
            asyncio.wait_for(loop.run_in_executor(None, *args), timeout))

async def scavenge_for_new_tasks(actor, conn, xvgd_c):
    other = "mister" if actor == "valet" else "valet"

    while conn.is_connected_or_connecting:

        try:
            listing = await future_async(
                conn.uagnet.unrecieved_packets, actor, timeout=1.5) or []
        except concurrent.futures._base.TimeoutError:
            listing = []
            log.info("recovered timeout scavenger")

        global scavenger_lock

        with scavenger_lock:
            tasks_id = xvgd_c.tasks_id + 1
            informal_pip = 0
            # log.info("scgr tasks_id + 1: %d " % tasks_id)
            # We are relying here on UAG alphanumerical sorting
            for i in listing:
                seq_id = uagNetworkHandle.pck_uri_to_idx(i.name)

                if seq_id < tasks_id:
                    continue

                if seq_id > tasks_id:
                    log.debug(other+": MISSING SEQ ORDER PACKET. ok...")
                    log.debug("%d vs %d" % (seq_id, tasks_id))
                    break

                xvgd_c.tasks[tasks_id] = PckTask(tasks_id, future_async(
                    conn.uagnet.commence_packet, actor, tasks_id, True, timeout=1.5), True)
                xvgd_c.tasks_id = tasks_id

                log.info("added %d" % tasks_id)

                tasks_id += 1
                informal_pip += 1

                if informal_pip > 5:
                    # rate limit
                   break


        if informal_pip:
            log.debug(other + ": Scavenger found %d pcks" % informal_pip)

        #await asyncio.sleep(0.67)
        await asyncio.sleep(NEXT_TICK)

async def actor_pipe_socket_to_uag(actor, conn):

    idx = 1
    sent_data = {}
    kept_data = {}

    while not conn.reader.at_eof():

        while sum(kept_data.values()) > ALARM_GARBAGE_SIZE:

            files = await future_async(conn.uagnet.unrecieved_packets, actor)

            new_sent = {}

            for i in files:
                key = uagNetworkHandle.pck_uri_to_idx(i.name)
                new_sent[key] = sent_data[key]

            kept_data = new_sent

            if sum(kept_data.values()) > BIG_GARBAGE_SIZE:
                await asyncio.sleep(0.067)

        log.debug(actor+': waiting for a read from server')

        data = await conn.reader.read(BUFFER_SIZE)

        if conn.reader.at_eof():
            data = b'!' + data
        else:
            data = b' ' + data

        log.debug(actor+': got a read from server')
        log.debug(actor+': sending data to MISTER %r (%d b) ' % (
            data, len(data)))

        future_async(conn.uagnet.send_packet, actor, idx, data)

        log.info(actor+':put %d(%d b)' % (idx, len(data)))

        kept_data[idx] = len(data)
        sent_data[idx] = len(data)

        idx += 1

    log.warn(actor+': reader closed')
    conn.is_connected_or_connecting = False
from collections import deque

async def actor_pipe_uag_to_socket(actor, conn):

    idx = 1

    first_time = True
    wrote_eof = False
    good_packet = False

    other = "mister" if actor == "valet" else "valet"

    xvgd_c = ScavengerContext()
    xvgd_c.tasks = {}

    while conn.is_connected_or_connecting and not wrote_eof:

        if good_packet:
            await asyncio.sleep(1)
            pass

        global scavenger_lock

        with scavenger_lock:
            if idx not in xvgd_c.tasks:
                xvgd_c.tasks[idx] = PckTask(idx, future_async(conn.uagnet.commence_packet, actor, idx, timeout=1.5), False)
                xvgd_c.tasks_id = idx
                log.info("actor added %d" % xvgd_c.tasks_id)

        if first_time:
            asyncio.ensure_future(scavenge_for_new_tasks(actor, conn, xvgd_c))
            first_time = False

        log.debug(other+": starting ordered parallelism")

        while idx in xvgd_c.tasks:
            task = xvgd_c.tasks[idx] # .popleft()
            del xvgd_c.tasks[idx]
            log.debug("tasks.len: %d"%len(xvgd_c.tasks))
            try:
                data, r, url, xvgd = await task.task
            except concurrent.futures._base.TimeoutError:
                log.info("recovered timeout")
                data, r, url, xvgd = (None, None, None, None)

            if task.idx != idx:
                log.error("The scavenger is severely broken")
                log.error("Got %d packet, expected %d, top is %d" % (task.idx, idx, xvgd_c.tasks_id))
                sys.exit()

            if data is not None:
                log.debug(other+': got data from VALET "%r" (%d b)' % (
                    data, len(data)))
                log.debug(other+': relaying VALETS data')

                conn.writer.write(data[1:])

                dlen = len(data)

                if not xvgd:
                    while True:
                        doc = await future_async(r.read, SMALL_BUFFER_SIZE)
                        conn.writer.write(doc)
                        dlen += len(doc)
                        if not doc:
                            break
                log.info(other+":feed %d(%d b),%s,xvgd:%d" % (idx, dlen,url, task.is_scavenged))

                if data[0] == b'!'[0]:
                    await conn.writer.drain()
                    conn.writer.write_eof()
                    wrote_eof = True
                    log.info(other+":feed eof %d" % idx)
                    break

                future_async(conn.uagnet.ack_packet, actor, idx)

                idx += 1
                good_packet = True
            else:
                log.debug(other+": when polling uag, data was None")
                await asyncio.sleep(NEXT_TICK)

    log.warn(other+': writer closed')


async def mister_contact_client(uag, client_reader, client_writer):

    log.info("New Connection")

    conn = connectionHandle(uagNetworkHandle(uag))
    conn.writer = client_writer
    conn.reader = client_reader
    conn.uagnet.token = uagNetworkHandle.gen_token()
    await future_async(conn.uagnet.do_syn)

    conn.is_connected_or_connecting = True

    task = asyncio.ensure_future(actor_pipe_uag_to_socket('valet', conn))

    while True:
        data = await future_async(conn.uagnet.lookup_synack)

        if data is None:
            log.debug("waiting for synack: hasn't got it yet")
            # await asyncio.sleep(NEXT_TICK)
            continue

        if ListDir(False, "line-mister") not in data:
            log.debug("still waiting to synack from server")
            # await asyncio.sleep(NEXT_TICK)
            continue

        log.info("Connection established!")
        # await asyncio.sleep(NEXT_TICK)
        break

    await actor_pipe_socket_to_uag("mister", conn)


async def valet_contact_server(uag):

    # server is capable of only one connection at a time.
    while True:

        delayed_open = None

        conn = connectionHandle(uagNetworkHandle(uag))

        while True:
            data = await future_async(conn.uagnet.lookup_syns)

            if len(data):
                conn.uagnet.token = uagNetworkHandle.conn_uri_to_token(
                    data[0].name)

                conn.is_connected_or_connecting = True

                delayed_open = asyncio.ensure_future(asyncio.open_connection(
                    args.server.host, args.server.port))

                await future_async(conn.uagnet.do_synack)
                break

            # await asyncio.sleep(NEXT_TICK)

        log.info("VALET: new connection from MISTER %s" % conn.uagnet.token)

        conn.reader, conn.writer = await delayed_open

        log.info("VALET: established server conn for %s" % conn.uagnet.token)

        asyncio.ensure_future(actor_pipe_uag_to_socket('mister', conn))
        await actor_pipe_socket_to_uag("valet", conn)

async def watch_doge():
    while True:
        last_time = time.time()
        await asyncio.sleep(0.05)
        waited = time.time() - last_time
        if waited > 0.5:
            log.error("Hiccup (%f s)" % waited)
        else:
            # log.info('ok')
            pass

def init_method(uag):

    ls = uag.list_folder('.ms-ff-uag-tcp-data/')
    
    print(ls)
    
    if ls is None or ListDir(False, 'to-connect') not in ls:
        log.info("Initialising...")
        uag.create_folder(".ms-ff-uag-tcp-data/to-connect")
        uag.create_folder(".ms-ff-uag-tcp-data/")
        log.info("Initialized.")
    else:
        log.info("Already initialized")

def clean_method(uag, dirr):
    ls = uag.list_folder(dirr) or []

    for i in ls:
        print("clearing %s"%i.name)
        filedir = dirr+"/"+i.name
        print(filedir)
        if not i.is_file and i.name is not 'to-connect':
            clean_method(uag, filedir)
            uag.delete_file(filedir)
        elif i.is_file:
            uag.delete_file(filedir)


if __name__ == '__main__':

    log = logging.getLogger("")
    formatter = logging.Formatter("%(asctime)s %(levelname)s " +
                                  "[%(module)s:%(lineno)d] %(message)s")
    # setup console logging

    args = ARGS.parse_args()

    args.server = Address(args.server)
    args.client = Address(args.client)

    if args.quiet == 2:
        log.error('Logging error only')
        lvl = logging.ERROR
    elif args.quiet == 1:
        log.info('Logging info')
        lvl = logging.INFO
    elif args.quiet == 0:
        log.info('Logging debug')
        lvl = logging.DEBUG

    log.setLevel(lvl)
    ch = logging.StreamHandler()
    ch.setLevel(lvl)

    ch.setFormatter(formatter)
    log.addHandler(ch)
    
    CONFIG_PATH = os.path.join(sys.path[0], args.config)

    config = configparser.ConfigParser()
    config.read(os.path.join(CONFIG_PATH, 'creds.txt'))

    ctx = ssl.create_default_context(cafile=os.path.join(CONFIG_PATH, config['verify']['cert']))
    cj = CookieJar(
        DefaultCookiePolicy(
            rfc2965=True,
            strict_ns_domain=DefaultCookiePolicy.DomainStrict,
            blocked_domains=["ads.net", ".ads.net"]))

    opener = urllib.request.build_opener(
        urllib.request.HTTPSHandler(context=ctx),
        HTTPHandler(),
        urllib.request.HTTPCookieProcessor(cj),
        NoRedirect())

    uag = UAGSession(opener)
    uag.perform_auth()

    if args.init:
        init_method(uag)
    elif args.clean:
        clean_method(uag, '.ms-ff-uag-tcp-data')
        init_method(uag)
    # elif args.unit:
        # Unit tests would be of use
        # create_folder(opener, main_url, 'testing-folders')
        # pprint(list_folder(opener, main_url, ''))
        # pprint(get_content(opener, main_url, 'ms-ff-uag-tcp.md'))
        # put_file(opener, main_url, '00000000.bin', b'test')
        # delete_file(opener, main_url, 'testing-132-folders')
    else:
        ALLOW_REDIRECT = False
        loop = asyncio.get_event_loop()

        if signal is not None and sys.platform != 'win32':
            loop.add_signal_handler(signal.SIGINT, loop.stop)

        if args.server:
            f = asyncio.ensure_future(valet_contact_server(uag))
            log.info("Waiting for connection request")
        else:
            f = asyncio.start_server(
                lambda r, w: asyncio.ensure_future(
                    mister_contact_client(uag, r, w)),
                host=args.client.host, port=args.client.port)
            log.info("Server is listening on port 8000")

        asyncio.ensure_future(watch_doge())
        loop.run_until_complete(f)
        loop.run_forever()
